{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df857977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('scripts')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchinfo import summary\n",
    "from torch.utils import data\n",
    "import h5py\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "import os\n",
    "from CNNEvaluate import *\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "sys.path.append('../CaloChallenge/code')\n",
    "sys.path.append('CaloChallenge/code')\n",
    "from utils import *\n",
    "from models import *\n",
    "from XMLHandler import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6831761a",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385c48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cpu'\n",
    "binning_file=\"../CaloChallenge/code/binning_dataset_1_photons.xml\"\n",
    "config = '../configs/config_dataset1_photon.json'\n",
    "cls_lr = 0.0001\n",
    "cls_batch_size = 100\n",
    "cls_n_epochs = 50\n",
    "INPUT_FILE = 'generated_photons.h5'\n",
    "REFERENCE_FILE = '../CaloChallenge/Datasets/dataset_1_photons_2.hdf5'\n",
    "output_dir = 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2e444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = LoadJson(config)\n",
    "\n",
    "bins=XMLHandler(\"photon\", binning_file)\n",
    "NN_embed=NNConverter(bins=bins).to(device=device)\n",
    "cond_dim = dataset_config['COND_SIZE_UNET']\n",
    "layer_sizes = [16,16,32,32,32]\n",
    "mid_attn = dataset_config.get(\"MID_ATTN\", False)\n",
    "compress_Z = dataset_config.get(\"COMPRESS_Z\", False)\n",
    "E_embed = dataset_config.get(\"COND_EMBED\", 'sin')\n",
    "\n",
    "RZ_shape = dataset_config['SHAPE_PAD'][1:]\n",
    "\n",
    "R_Z_inputs = dataset_config.get('R_Z_INPUT', False)\n",
    "phi_inputs = dataset_config.get('PHI_INPUT', False)\n",
    "\n",
    "in_channels = 1\n",
    "\n",
    "if(R_Z_inputs): in_channels = 3\n",
    "if(phi_inputs): in_channels += 1\n",
    "\n",
    "calo_summary_shape = list(copy.copy(RZ_shape))\n",
    "calo_summary_shape.insert(0, 1)\n",
    "calo_summary_shape[1] = in_channels\n",
    "\n",
    "calo_summary_shape[0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715cfb1c",
   "metadata": {},
   "source": [
    "### File Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85bcf191",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = h5py.File(INPUT_FILE, 'r')\n",
    "reference_file = h5py.File(REFERENCE_FILE, 'r')\n",
    "\n",
    "reference_showers = reference_file['showers']\n",
    "reference_energies = reference_file['incident_energies']\n",
    "\n",
    "reference_data = np.hstack((reference_showers, reference_energies, np.zeros_like(reference_energies)))\n",
    "\n",
    "source_showers = source_file['showers']\n",
    "source_energies = source_file['incident_energies']\n",
    "\n",
    "source_data = np.hstack((source_showers, source_energies, np.ones_like(source_energies)))\n",
    "\n",
    "train, test, val = ttv_split(source_data, reference_data)\n",
    "\n",
    "\n",
    "\n",
    "train_data = data.TensorDataset(torch.tensor(train).float())\n",
    "test_data = data.TensorDataset(torch.tensor(test).float())\n",
    "val_data = data.TensorDataset(torch.tensor(val).float())\n",
    "\n",
    "\n",
    "train_dataloader = data.DataLoader(train_data, batch_size=cls_batch_size, shuffle=True)\n",
    "test_dataloader = data.DataLoader(test_data, batch_size= cls_batch_size, shuffle=False)\n",
    "val_dataloader = data.DataLoader(val_data, batch_size=cls_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f605d3",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a075df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94185539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 311665 parameters\n"
     ]
    }
   ],
   "source": [
    "model = CNN(cond_dim = cond_dim, out_dim = 1, channels = in_channels, layer_sizes = layer_sizes\n",
    "            ,cylindrical = dataset_config.get('CYLINDRICAL', False),\n",
    "            data_shape = calo_summary_shape, NN_embed=NN_embed, RZ_shape = RZ_shape, mid_attn = mid_attn)\n",
    "\n",
    "total_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Model has {} parameters\".format(int(total_parameters)))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cls_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7b5bdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1, step    0 / 1452; loss 1.7897\n",
      "Epoch   1, step  726 / 1452; loss 0.7219\n",
      "Accuracy on training set is 0.5056404958677686\n",
      "Accuracy on test set is 0.5121900826446281\n",
      "AUC on test set is 0.5121900826446281\n",
      "BCE loss of test set is 0.7023, JSD of the two dists is -0.0131\n",
      "Epoch   2, step    0 / 1452; loss 0.6819\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_cls(model, train_dataloader, test_dataloader, optimizer, cls_n_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = load_classifier(classifier, args)\n",
    "with torch.no_grad():\n",
    "    print(\"Now looking at independent dataset:\")\n",
    "    eval_acc, eval_auc, eval_JSD = evaluate_cls(classifier, val_dataloader, device,\n",
    "                                                final_eval=True,\n",
    "                                                calibration_data=test_dataloader)\n",
    "    print(\"Final result of classifier test (AUC / JSD):\")\n",
    "    print(\"{:.4f} / {:.4f}\".format(eval_auc, eval_JSD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3c2d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_cls(model, data_train, data_test, optim, cls_n_epochs, device):\n",
    "    \"\"\" train the model and evaluate along the way\"\"\"\n",
    "    best_eval_acc = float('-inf')\n",
    "    best_epoch = -1\n",
    "    try:\n",
    "        for i in range(cls_n_epochs):\n",
    "            train_cls(model, data_train, optim, i, device)\n",
    "            with torch.no_grad():\n",
    "                eval_acc, _, _ = evaluate_cls(model, data_test, device)\n",
    "            if eval_acc > best_eval_acc:\n",
    "                best_eval_acc = eval_acc\n",
    "                best_epoch = i+1\n",
    "                filename = 'CNN_1_photons.pt'\n",
    "                torch.save({'model_state_dict':model.state_dict()},\n",
    "                           os.path.join(output_dir, filename))\n",
    "            if eval_acc == 1.:\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        # training can be cut short with ctrl+c, for example if overfitting between train/test set\n",
    "        # is clearly visible\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77903328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cls(model, data_train, optim, epoch, device):\n",
    "    \"\"\" train one step \"\"\"\n",
    "    model.train()\n",
    "    for i, data_batch in enumerate(data_train):\n",
    "        \n",
    "        data_batch = data_batch[0].to(device)\n",
    "        \n",
    "        \n",
    "        #input_vector, target_vector = torch.split(data_batch, [data_batch.size()[1]-1, 1], dim=1)\n",
    "        input_vector, cond_vector, target_vector = data_batch[:, :-2], data_batch[:,-2], data_batch[:, -1]\n",
    "        \n",
    "        output_vector = model(input_vector, cond_vector)\n",
    "        \n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        loss = criterion(output_vector, target_vector.unsqueeze(1))\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if i % (len(data_train)//2) == 0:\n",
    "            print('Epoch {:3d}, step {:4d} / {}; loss {:.4f}'.format(\n",
    "                epoch+1, i, len(data_train), loss.item()))\n",
    "        # PREDICTIONS\n",
    "        pred = torch.round(torch.sigmoid(output_vector.detach()))\n",
    "        target = torch.round(target_vector.detach())\n",
    "        if i == 0:\n",
    "            res_true = target\n",
    "            res_pred = pred\n",
    "        else:\n",
    "            res_true = torch.cat((res_true, target), 0)\n",
    "            res_pred = torch.cat((res_pred, pred), 0)\n",
    "\n",
    "    try:\n",
    "        print(\"Accuracy on training set is\",\n",
    "          accuracy_score(res_true.cpu(), np.clip(res_pred.cpu(), 0., 1.0)))\n",
    "    except:\n",
    "        print(\"Nans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1d4550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cls(model, data_test, device, final_eval=False, calibration_data=None):\n",
    "    \"\"\" evaluate on test set \"\"\"\n",
    "    model.eval()\n",
    "    for j, data_batch in enumerate(data_test):\n",
    "        \n",
    "        data_batch = data_batch[0].to(device)\n",
    "        input_vector, cond_vector, target_vector = data_batch[:, :-2], data_batch[:, -2], data_batch[:, -1]\n",
    "        \n",
    "        \n",
    "        output_vector = model(input_vector, cond_vector)\n",
    "        pred = output_vector.reshape(-1)\n",
    "        target = target_vector.double()\n",
    "        if j == 0:\n",
    "            result_true = target\n",
    "            result_pred = pred\n",
    "        else:\n",
    "            result_true = torch.cat((result_true, target), 0)\n",
    "            result_pred = torch.cat((result_pred, pred), 0)\n",
    "    BCE = torch.nn.BCEWithLogitsLoss()(result_pred, result_true)\n",
    "    result_pred = torch.round(torch.sigmoid(result_pred)).cpu().numpy()\n",
    "    result_true = result_true.cpu().numpy()\n",
    "    result_pred = np.clip(np.round(result_pred), 0., 1.0)\n",
    "    #print(np.amin(result_pred), np.amax(result_pred), np.sum(np.isnan(result_pred)))\n",
    "    try:\n",
    "        eval_acc = accuracy_score(result_true, result_pred)\n",
    "    except:\n",
    "        print(\"Nans\")\n",
    "        result_pred[np.isnan(result_pred)] = 0.5\n",
    "        eval_acc = accuracy_score(result_true, result_pred)\n",
    "    print(\"Accuracy on test set is\", eval_acc)\n",
    "    eval_auc = roc_auc_score(result_true, result_pred)\n",
    "    print(\"AUC on test set is\", eval_auc)\n",
    "    JSD = - BCE + np.log(2.)\n",
    "    print(\"BCE loss of test set is {:.4f}, JSD of the two dists is {:.4f}\".format(BCE,\n",
    "                                                                                  JSD/np.log(2.)))\n",
    "    if final_eval:\n",
    "        prob_true, prob_pred = calibration_curve(result_true, result_pred, n_bins=10)\n",
    "        print(\"unrescaled calibration curve:\", prob_true, prob_pred)\n",
    "        calibrator = calibrate_classifier(model, calibration_data, device)\n",
    "        rescaled_pred = calibrator.predict(result_pred)\n",
    "        eval_acc = accuracy_score(result_true, np.clip(np.round(rescaled_pred), 0., 1.0))\n",
    "        print(\"Rescaled accuracy is\", eval_acc)\n",
    "        eval_auc = roc_auc_score(result_true, rescaled_pred)\n",
    "        print(\"rescaled AUC of dataset is\", eval_auc)\n",
    "        prob_true, prob_pred = calibration_curve(result_true, rescaled_pred, n_bins=10)\n",
    "        print(\"rescaled calibration curve:\", prob_true, prob_pred)\n",
    "        # calibration was done after sigmoid, therefore only BCELoss() needed here:\n",
    "        BCE = torch.nn.BCELoss()(torch.tensor(rescaled_pred), torch.tensor(result_true))\n",
    "        JSD = - BCE.cpu().numpy() + np.log(2.)\n",
    "        otp_str = \"rescaled BCE loss of test set is {:.4f}, \"+\\\n",
    "            \"rescaled JSD of the two dists is {:.4f}\"\n",
    "        print(otp_str.format(BCE, JSD/np.log(2.)))\n",
    "    return eval_acc, eval_auc, JSD/np.log(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bcd0b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_classifier(model, calibration_data, device):\n",
    "    \n",
    "    \"\"\" reads in calibration data and performs a calibration with isotonic regression\"\"\"\n",
    "    model.eval()\n",
    "    assert calibration_data is not None, (\"Need calibration data for calibration!\")\n",
    "    for j, data_batch in enumerate(calibration_data):\n",
    "        \n",
    "        \n",
    "        data_batch = data_batch[0].to(device)\n",
    "        input_vector, target_vector = data_batch[:, :-1], data_batch[:, -1]\n",
    "        output_vector = model(input_vector)\n",
    "        pred = torch.sigmoid(output_vector).reshape(-1)\n",
    "        target = target_vector.to(torch.float64)\n",
    "        if j == 0:\n",
    "            result_true = target\n",
    "            result_pred = pred\n",
    "        else:\n",
    "            result_true = torch.cat((result_true, target), 0)\n",
    "            result_pred = torch.cat((result_pred, pred), 0)\n",
    "    result_true = result_true.cpu().numpy()\n",
    "    result_pred = result_pred.cpu().numpy()\n",
    "    iso_reg = IsotonicRegression(out_of_bounds='clip', y_min=1e-6, y_max=1.-1e-6).fit(result_pred,\n",
    "                                                                                      result_true)\n",
    "    return iso_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f79ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classifier(constructed_model, output_dir, filename, device):\n",
    "    \"\"\" loads a saved model \"\"\"\n",
    "    checkpoint = torch.load(os.path.join(output_dir, filename),\n",
    "                            map_location=device)\n",
    "    constructed_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    constructed_model.to(device)\n",
    "    constructed_model.eval()\n",
    "    print('classifier loaded successfully')\n",
    "    return constructed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc201e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
